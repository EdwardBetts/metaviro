We perform an analysis of virus hardness when we restrict to viruses. 


```{r libraries}
source("prepare_data.R")

```

* Classes of viruses 

```{r }
annotated_virus_kmers[,.N,by='Host'][order(N)] #Vast majority of plants viruses, followed by bacteria then vertebrates. 
annotated_virus_kmers[,.N,by='Group'][order(N)] #Vast majority of plants viruses, followed by bacteria then vertebrates. 
dcast(annotated_virus_kmers,Group~Host)

```


We plot a PCA of the 3-mers and check any class overlap 

```{r }
ggplot(normalized_kmers,aes(x=Comp.1,y=Comp.2,colour=Host))+geom_point(alpha=0.5)+facet_wrap(~Host)
```

We load the kNN

```{r fastKNN}
source("fast_sparse_knn.R")
labels_to_return=c("Group","SubGroup","Host","Status","Segments","Genes","Proteins","org","org.GC","species")

# quick check 
some_obs=sample(normalized_kmers$idx,100)
foo2=compute_closest2(feat_matrix=normalized_kmers, selected_features=kmers_columns, selected_obs=some_obs, n_closer=23, selected_labels=labels_to_return)
foo2[rank==1]
unique(foo2$src)
foo2$tgt

```

# Computations 


```{r}

n_closer_neighbors=73
input_size=nrow(normalized_kmers)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)

# Single unit test
compute_closest2(normalized_kmers,kmers_columns,1,50,selected_labels=labels_to_return)

res= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% compute_closest2(normalized_kmers,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))
# save(res,file="73_closes_virus_neighbors.RData")

```

* How many viruses are close to viruses of the same group ? 

```{r }
res_no_diag=res[src!=tgt]
res_no_diag[src==1]

res_neighbors_group=data.table(dcast(res_no_diag,src+src_Group+src_SubGroup~tgt_Group))
res_neighbors_group[,.N,by=src_Group]

res_neighbors_group_m=melt(res_neighbors_group,id.vars=c("src","src_Group","src_SubGroup"))
res_neighbors_group_m[,mismatch:=F]
res_neighbors_group_m[src_Group!=variable,mismatch:=T]

res_neighbors_group_matches=res_neighbors_group_m[,sum(value),by=list(src,src_Group,src_SubGroup,mismatch)]
res_neighbors_group_matches_disagreeing=res_neighbors_group_matches[mismatch==T]
res_neighbors_group_matches_disagreeing[,mean(V1),by=src_Group][order(V1)]

ggplot(res_neighbors_group_matches_disagreeing,aes(x=factor(V1),fill=src_Group))+geom_bar()


```

We restrict to majority classes and perform balanced sampling 

```{r }
majority_group=normalized_kmers_pca[,.N,by=Group][order(N)][N>1000,Group]
# normalized_kmers_pca_maj_group=normalized_kmers_pca[Group %in% majority_group]

# balanced sampling 


normalized_kmers_pca$idx=1:nrow(normalized_kmers_pca)

n_tgt_samples_per_group=normalized_kmers_pca[,.N,by=Group][order(N)][N>1000,min(N)] # 1490 contigs 

downsample_idx=c(
	sample(normalized_kmers_pca[Group == majority_group[1],idx],1490),
	sample(normalized_kmers_pca[Group == majority_group[2],idx],1490),
	sample(normalized_kmers_pca[Group == majority_group[3],idx],1490),
	sample(normalized_kmers_pca[Group == majority_group[4],idx],1490))

normalized_kmers_pca_ds=normalized_kmers_pca[downsample_idx,]
normalized_kmers_pca_ds[,.N,by=Group]
normalized_kmers_pca_ds$idx=1:nrow(normalized_kmers_pca_ds)
```

We compute the closest neighbors restricted to the majority group

```{r }
input_size=nrow(normalized_kmers_pca_ds)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)

res_maj_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% 
	# compute_closest(mixed_3mers,mixed_3mers_count_cols, i[,1],n_closer=n_closer_neighbors,selected_labels=c("class","species","sequence_description")))
	compute_closest(normalized_kmers_pca_ds,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))
save(res_maj_group,file="73_closes_virus_neighbors_maj_groups.RData")
```


We tabulate 

```{r }
res_maj_group_no_diag=res_maj_group[src!=tgt & rank<=53]
# res_maj_group_no_diag[src==1]

res_maj_group_neighbors_group=data.table(dcast(res_maj_group_no_diag,src+src_Group~tgt_Group))
res_maj_group_neighbors_group$src_Group=as.character(res_maj_group_neighbors_group$src_Group)
res_maj_group_neighbors_group[,.N,by=src_Group]


res_maj_group_neighbors_group_m=melt(res_maj_group_neighbors_group,id.vars=c("src","src_Group"))
res_maj_group_neighbors_group_m[,.N,by=src_Group]
res_maj_group_neighbors_group_m[,.N,by=variable]


res_maj_group_neighbors_group_m[,mismatch:=F]
res_maj_group_neighbors_group_m[src_Group!=variable,mismatch:=T]

res_maj_group_neighbors_group_matches=res_maj_group_neighbors_group_m[,sum(value),by=list(src,src_Group,src_SubGroup,mismatch)]
res_maj_group_neighbors_group_matches_disagreeing=res_maj_group_neighbors_group_matches[mismatch==T]
res_maj_group_neighbors_group_matches_disagreeing[,mean(V1),by=src_Group][order(V1)]

group_summaries=res_maj_group_neighbors_group_matches_disagreeing[,sum(V1),by=list(src,src_Group)]


ggplot(group_summaries,aes(x=factor(V1),fill=src_Group))+geom_bar()

```

How many have a majority in their neighbor ? 

```{r }
res_neighbors_group_matches
res_neighbors_group_matches[V1>=36] # more than half 

```


* Are virus subgroup more compact than groups? 

```{r }

most_frequent_subgroups=tail(normalized_kmers_pca[,.N,by=SubGroup][order(N)],n=4)$SubGroup
min_size=min(tail(normalized_kmers_pca[,.N,by=SubGroup][order(N)],n=4)$N)
# Downsample the 6 most frequent subGroups 


downsample_idx=unlist(llply(most_frequent_subgroups,function(g){sample(normalized_kmers_pca[SubGroup == g,idx],min_size)}))
normalized_kmers_pca_ds_SG=normalized_kmers_pca[downsample_idx]
normalized_kmers_pca_ds_SG[,.N,by=Group]
normalized_kmers_pca_ds_SG[,.N,by=SubGroup]


input_size=nrow(normalized_kmers_pca_ds_SG)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)

res_maj_sub_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% 
	compute_closest(normalized_kmers_pca_ds_SG,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))

```


We tabulate 

```{r }
res_maj_sub_group_no_diag=res_maj_sub_group[src!=tgt & rank<=53]
# res_maj_sub_group_no_diag[src==1]

res_maj_sub_group_neighbors_group=data.table(dcast(res_maj_sub_group_no_diag,src+src_Group+src_SubGroup~tgt_SubGroup))
res_maj_sub_group_neighbors_group$src_SubGroup=as.character(res_maj_sub_group_neighbors_group$src_SubGroup)
res_maj_sub_group_neighbors_group[,.N,by=src_SubGroup]


res_maj_sub_group_neighbors_sub_group_m=melt(res_maj_sub_group_neighbors_group,id.vars=c("src","src_Group","src_SubGroup"))
res_maj_sub_group_neighbors_sub_group_m[src==1]
head(res_maj_sub_group_neighbors_sub_group_m[value!=0][order(value)],n=100)
res_maj_sub_group_neighbors_sub_group_m[,.N,by=src_SubGroup]
res_maj_sub_group_neighbors_sub_group_m[,.N,by=variable]
res_maj_sub_group_neighbors_sub_group_m[src %in% c(3,7,8)][order(src)]


res_maj_sub_group_neighbors_sub_group_m[,mismatch:=F]
res_maj_sub_group_neighbors_sub_group_m[src_SubGroup!=variable,mismatch:=T]
head(res_maj_sub_group_neighbors_sub_group_m[mismatch==T][order(src)],n=20)

res_maj_sub_group_neighbors_sub_group_matches=res_maj_sub_group_neighbors_sub_group_m[,sum(value),by=list(src,src_SubGroup,variable,mismatch)]
res_maj_sub_group_neighbors_sub_group_matches_disagreeing=res_maj_sub_group_neighbors_sub_group_matches[mismatch==T]
sub_groups_summaries=res_maj_sub_group_neighbors_sub_group_matches_disagreeing[,sum(V1),by=list(src,src_SubGroup,mismatch)]

ggplot(sub_groups_summaries,aes(x=factor(V1),fill=src_SubGroup))+geom_bar()

```


We PCA and plot 

```{r }
pc_kmers=princomp(normalized_kmers_pca_ds_SG[,kmers_columns,with=F])

coord_pca=predict(pc_kmers)[,1:3]
colnames(coord_pca)=paste("vir_SG",colnames(coord_pca),sep="")

normalized_kmers_pca_ds_SG=cbind(normalized_kmers_pca_ds_SG,coord_pca)

ggplot(normalized_kmers_pca_ds_SG,aes(x=vir_SGComp.1,y=vir_SGComp.2,colour=SubGroup))+geom_point()+facet_wrap(~SubGroup)
ggplot(normalized_kmers_pca_ds_SG,aes(x=vir_SGComp.2,y=vir_SGComp.3,colour=SubGroup))+geom_point()+facet_wrap(~SubGroup)


```


**It seems that sub-groups are very easy to discriminate in euclidean space, we check with a naive kNN** 


```{r }
library(caret)
library(mlbench)

inTrain <- createDataPartition(y = normalized_kmers_pca_ds_SG$SubGroup, p = .9, list = FALSE)
training <- normalized_kmers_pca_ds_SG[ inTrain[,1],c(kmers_columns,"SubGroup"),with=F]
testing  <- normalized_kmers_pca_ds_SG[-inTrain[,1],c(kmers_columns,"SubGroup"),with=F]

knn3_results=knn3Train(training[,kmers_columns,with=F],testing[,kmers_columns,with=F],as.character(training$SubGroup),k=9,prob=F)
confusionMatrix(knn3_results,as.character(testing$SubGroup))


```

Indeed we have pretty good performances. If we instead focus on the four majority group :

```{r }

normalized_kmers_pca$idx=1:nrow(normalized_kmers_pca)
most_frequent_subgroups=tail(normalized_kmers_pca[,.N,by=SubGroup][SubGroup!="unclassified"][order(N)],n=4)$SubGroup
min_size=min(tail(normalized_kmers_pca[,.N,by=SubGroup][SubGroup!="unclassified"][order(N)],n=4)$N)
# Downsample the 6 most frequent subGroups 


downsample_idx=unlist(llply(most_frequent_subgroups,function(g){sample(normalized_kmers_pca[SubGroup == g,idx],min_size)}))
normalized_kmers_pca_ds_SG=normalized_kmers_pca[downsample_idx]
normalized_kmers_pca_ds_SG[,.N,by=Group]
normalized_kmers_pca_ds_SG[,.N,by=SubGroup]

inTrain <- createDataPartition(y = normalized_kmers_pca_ds_SG$SubGroup, p = .8, list = FALSE)
training <- normalized_kmers_pca_ds_SG[ inTrain[,1],c(kmers_columns,"SubGroup"),with=F]
testing  <- normalized_kmers_pca_ds_SG[-inTrain[,1],c(kmers_columns,"SubGroup"),with=F]

knn3_results=knn3Train(training[,kmers_columns,with=F],testing[,kmers_columns,with=F],as.character(training$SubGroup),k=7,prob=F)
confusionMatrix(knn3_results,as.character(testing$SubGroup))


```

We instead try to classify groups 

```{r }
normalized_kmers_pca$idx=1:nrow(normalized_kmers_pca)
most_frequent_groups=tail(normalized_kmers_pca[,.N,by=Group][Group!="unclassified"][order(N)],n=4)$Group
min_size=min(tail(normalized_kmers_pca[,.N,by=Group][Group!="unclassified"][order(N)],n=4)$N)
# Downsample the 6 most frequent Groups 


downsample_idx=unlist(llply(most_frequent_groups,function(g){sample(normalized_kmers_pca[Group == g,idx],min_size)}))
normalized_kmers_pca_ds_SG=normalized_kmers_pca[downsample_idx]
normalized_kmers_pca_ds_SG[,.N,by=Group]

inTrain <- createDataPartition(y = normalized_kmers_pca_ds_SG$Group, p = .8, list = FALSE)
training <- normalized_kmers_pca_ds_SG[ inTrain[,1],c(kmers_columns,"Group"),with=F]
testing  <- normalized_kmers_pca_ds_SG[-inTrain[,1],c(kmers_columns,"Group"),with=F]

knn3_results=knn3Train(training[,kmers_columns,with=F],testing[,kmers_columns,with=F],as.character(training$Group),k=7,prob=F)
confusionMatrix(knn3_results,as.character(testing$Group))

```


Let's add some plant contigs 


```{r }
plant_kmers=all_instances_kmers[class=="euk"]
plant_kmers_ds=plant_kmers[sample(1:nrow(plant_kmers),min_size),]

plant_kmers_ds_counts=plant_kmers_ds[,kmers_columns,with=F]/plant_kmers_ds$sequence_length
plant_kmers_ds_counts$Group="euk"

hybrid_dset=rbind(normalized_kmers_pca[,c(kmers_columns,"Group"),with=F],plant_kmers_ds_counts)
hybrid_dset$idx=1:nrow(hybrid_dset)

# Determine groups to keep
most_frequent_groups=tail(hybrid_dset[,.N,by=Group][Group!="unclassified"][order(N)],n=5)$Group
# Determine minimal number of items per groups 
min_size=min(tail(hybrid_dset[,.N,by=Group][Group!="unclassified"][order(N)],n=5)$N)
# Balanced downsample by groups
downsample_idx=unlist(llply(most_frequent_groups,function(g){sample(hybrid_dset[Group == g,idx],min_size)}))

hybrid_dset_ds=hybrid_dset[downsample_idx]
hybrid_dset_ds[,.N,by=Group]


inTrain <- createDataPartition(y = hybrid_dset_ds$Group, p = .8, list = FALSE)
training <- hybrid_dset_ds[ inTrain[,1],c(kmers_columns,"Group"),with=F]
testing  <- hybrid_dset_ds[-inTrain[,1],c(kmers_columns,"Group"),with=F]

knn3_results=knn3Train(training[,kmers_columns,with=F],testing[,kmers_columns,with=F],as.character(training$Group),k=7,prob=F)
confusionMatrix(knn3_results,as.character(testing$Group))

```





# Determining a p-value of mean class disagreement 

We consider the hardness of the group classification tasks. 

```{r }
n_closer_neighbors=73
glimpse(normalized_kmers)
most_frequent_groups=tail(normalized_kmers[,.N,by=Group][order(N)],n=4)$Group
min_size=min(tail(normalized_kmers[,.N,by=Group][order(N)],n=4)$N)
labels_to_return=c("Group","SubGroup","Host","Status","Segments","Genes","Proteins","org","org.GC","species")


downsample_idx=unlist(llply(most_frequent_groups,function(g){sample(normalized_kmers[Group == g,idx],min_size)}))
normalized_kmers_ds_SG=normalized_kmers[downsample_idx]
normalized_kmers_ds_SG[,.N,by=Group]
normalized_kmers_ds_SG$idx=1:nrow(normalized_kmers_ds_SG)
input_size=nrow(normalized_kmers_ds_SG)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)
res_maj_by_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% compute_closest2(normalized_kmers_ds_SG,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))


# permute class labels 
res_maj_by_group_orig=res_maj_by_group
res_maj_by_group$tgt_Group=sample(res_maj_by_group$tgt_Group)
# unpermute 
# res_maj_by_group$tgt_Group=res_maj_by_group_orig$tgt_Group


res_maj_by_group_no_diag=res_maj_by_group[src!=tgt & rank<=20]
# res_maj_by_group_no_diag[src==1]

res_maj_by_group_neighbors_group=data.table(dcast(res_maj_by_group_no_diag,src+src_Group~tgt_Group))
res_maj_by_group_neighbors_group$src_Group=as.character(res_maj_by_group_neighbors_group$src_Group)
res_maj_by_group_neighbors_group[,.N,by=src_Group]


res_maj_by_group_neighbors_sub_group_m=melt(res_maj_by_group_neighbors_group,id.vars=c("src","src_Group"))
res_maj_by_group_neighbors_sub_group_m[,mismatch:=F]
res_maj_by_group_neighbors_sub_group_m[src_Group!=variable,mismatch:=T]

res_maj_by_group_neighbors_sub_group_matches=res_maj_by_group_neighbors_sub_group_m[,sum(value),by=list(src,src_Group,variable,mismatch)]
res_maj_by_group_neighbors_sub_group_matches_disagreeing=res_maj_by_group_neighbors_sub_group_matches[mismatch==T]
sub_groups_summaries=res_maj_by_group_neighbors_sub_group_matches_disagreeing[,sum(V1),by=list(src,src_Group,mismatch)]
tbl_df(sub_groups_summaries) %.% group_by(src_Group) %.% summarise(a_mean=mean(V1))
ggplot(sub_groups_summaries,aes(x=factor(V1,levels=0:n_closer_neighbors),fill=src_Group))+geom_histogram()
```

We make a function to return the sub_groups 

```{r }
source("fast_sparse_knn.R")
determine_disagreeing(53)
normalized_kmers
```


# Short reads problem


```{r }
source("prepare_data_short_reads.R")


n_closer_neighbors=51
glimpse(short_virus_kmers_norm)
most_frequent_groups=tail(short_virus_kmers_norm[,.N,by=Group][order(N)],n=4)$Group
min_size=min(tail(short_virus_kmers_norm[,.N,by=Group][order(N)],n=4)$N)
labels_to_return=c("Group","SubGroup","Host","Status","Segments","Genes","Proteins","org","org.GC","species")


downsample_idx=unlist(llply(most_frequent_groups,function(g){sample(short_virus_kmers_norm[Group == g,idx],min_size)}))
short_virus_kmers_norm_ds_SG=short_virus_kmers_norm[downsample_idx]
short_virus_kmers_norm_ds_SG[,.N,by=Group]
short_virus_kmers_norm_ds_SG$idx=1:nrow(short_virus_kmers_norm_ds_SG)
input_size=nrow(short_virus_kmers_norm_ds_SG)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)
res_maj_by_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% compute_closest2(short_virus_kmers_norm_ds_SG,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))


# permute class labels 
res_maj_by_group_orig=res_maj_by_group
# res_maj_by_group$tgt_Group=sample(res_maj_by_group$tgt_Group)
# unpermute 
# res_maj_by_group$tgt_Group=res_maj_by_group_orig$tgt_Group


res_maj_by_group_no_diag=res_maj_by_group[src!=tgt & rank<=n_closer_neighbors]
# res_maj_by_group_no_diag[src==1]

res_maj_by_group_neighbors_group=data.table(dcast(res_maj_by_group_no_diag,src+src_Group~tgt_Group))
res_maj_by_group_neighbors_group$src_Group=as.character(res_maj_by_group_neighbors_group$src_Group)
res_maj_by_group_neighbors_group[,.N,by=src_Group]


res_maj_by_group_neighbors_sub_group_m=melt(res_maj_by_group_neighbors_group,id.vars=c("src","src_Group"))
res_maj_by_group_neighbors_sub_group_m[,mismatch:=F]
res_maj_by_group_neighbors_sub_group_m[src_Group!=variable,mismatch:=T]

res_maj_by_group_neighbors_sub_group_matches=res_maj_by_group_neighbors_sub_group_m[,sum(value),by=list(src,src_Group,variable,mismatch)]
res_maj_by_group_neighbors_sub_group_matches_disagreeing=res_maj_by_group_neighbors_sub_group_matches[mismatch==T]
sub_groups_summaries=res_maj_by_group_neighbors_sub_group_matches_disagreeing[,sum(V1),by=list(src,src_Group,mismatch)]
tbl_df(sub_groups_summaries) %.% group_by(src_Group) %.% summarise(a_mean=mean(V1))
ggplot(sub_groups_summaries,aes(x=factor(V1,levels=0:n_closer_neighbors),fill=src_Group))+geom_histogram()


```




# Long reads results 

```{r }
source("prepare_data_long_reads.R")


n_closer_neighbors=51
glimpse(long_virus_kmers_norm)
most_frequent_groups=tail(long_virus_kmers_norm[,.N,by=Group][order(N)],n=4)$Group
min_size=min(tail(long_virus_kmers_norm[,.N,by=Group][order(N)],n=4)$N)
labels_to_return=c("Group","SubGroup","Host","Status","Segments","Genes","Proteins","org","org.GC","species")


downsample_idx=unlist(llply(most_frequent_groups,function(g){sample(long_virus_kmers_norm[Group == g,idx],min_size)}))
long_virus_kmers_norm_ds_SG=long_virus_kmers_norm[downsample_idx]
long_virus_kmers_norm_ds_SG[,.N,by=Group]
long_virus_kmers_norm_ds_SG$idx=1:nrow(long_virus_kmers_norm_ds_SG)
input_size=nrow(long_virus_kmers_norm_ds_SG)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)
res_maj_by_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% compute_closest2(long_virus_kmers_norm_ds_SG,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))


# permute class labels 
res_maj_by_group_orig=res_maj_by_group
# res_maj_by_group$tgt_Group=sample(res_maj_by_group$tgt_Group)
# unpermute 
# res_maj_by_group$tgt_Group=res_maj_by_group_orig$tgt_Group


res_maj_by_group_no_diag=res_maj_by_group[src!=tgt & rank<=n_closer_neighbors]
# res_maj_by_group_no_diag[src==1]

res_maj_by_group_neighbors_group=data.table(dcast(res_maj_by_group_no_diag,src+src_Group~tgt_Group))
res_maj_by_group_neighbors_group$src_Group=as.character(res_maj_by_group_neighbors_group$src_Group)
res_maj_by_group_neighbors_group[,.N,by=src_Group]


res_maj_by_group_neighbors_sub_group_m=melt(res_maj_by_group_neighbors_group,id.vars=c("src","src_Group"))
res_maj_by_group_neighbors_sub_group_m[,mismatch:=F]
res_maj_by_group_neighbors_sub_group_m[src_Group!=variable,mismatch:=T]

res_maj_by_group_neighbors_sub_group_matches=res_maj_by_group_neighbors_sub_group_m[,sum(value),by=list(src,src_Group,variable,mismatch)]
res_maj_by_group_neighbors_sub_group_matches_disagreeing=res_maj_by_group_neighbors_sub_group_matches[mismatch==T]
sub_groups_summaries=res_maj_by_group_neighbors_sub_group_matches_disagreeing[,sum(V1),by=list(src,src_Group,mismatch)]
tbl_df(sub_groups_summaries) %.% group_by(src_Group) %.% summarise(a_mean=mean(V1))
ggplot(sub_groups_summaries,aes(x=factor(V1,levels=0:n_closer_neighbors),fill=src_Group))+geom_histogram()


```


Definitely better


We consider the sub-group classification probem

```{r }

n_closer_neighbors=50
glimpse(long_virus_kmers_norm)

most_frequent_subgroups=tail(long_virus_kmers_norm[SubGroup!="unclassified"][,.N,by=SubGroup][order(N)],n=8)$SubGroup
min_size=long_virus_kmers_norm[SubGroup %in% most_frequent_subgroups,.N,by=SubGroup][,min(N)]

labels_to_return=c("Group","SubGroup","Host","Status","Segments","Genes","Proteins","org","org.GC","species")


downsample_idx=unlist(llply(most_frequent_subgroups,function(g){sample(long_virus_kmers_norm[SubGroup == g,idx],min_size)}))

long_virus_kmers_norm_ds_SG=long_virus_kmers_norm[downsample_idx]
long_virus_kmers_norm_ds_SG[,.N,by=SubGroup]
long_virus_kmers_norm_ds_SG$idx=1:nrow(long_virus_kmers_norm_ds_SG)
input_size=nrow(long_virus_kmers_norm_ds_SG)
nas_to_add=((input_size %/% n_cores)+1)*n_cores - input_size
input_splits= matrix(c(1:input_size,rep(NA,nas_to_add)),byrow=T,ncol=n_cores)
res_maj_by_group= data.table(foreach(i=iter(input_splits,by='col'),.combine='rbind',.inorder=F) %dopar% compute_closest2(long_virus_kmers_norm_ds_SG,kmers_columns,i[,1],n_closer_neighbors,selected_labels=labels_to_return))


# permute class labels 
res_maj_by_group_orig=res_maj_by_group
# res_maj_by_group$tgt_Group=sample(res_maj_by_group$tgt_Group)
# unpermute 
# res_maj_by_group$tgt_Group=res_maj_by_group_orig$tgt_Group


res_maj_by_group_no_diag=res_maj_by_group[src!=tgt & rank<=n_closer_neighbors]
# res_maj_by_group_no_diag[src==1]

res_maj_by_group_neighbors_group=data.table(dcast(res_maj_by_group_no_diag,src+src_SubGroup~tgt_SubGroup))
res_maj_by_group_neighbors_group$src_SubGroup=as.character(res_maj_by_group_neighbors_group$src_SubGroup)
res_maj_by_group_neighbors_group[,.N,by=src_SubGroup]


res_maj_by_group_neighbors_sub_group_m=melt(res_maj_by_group_neighbors_group,id.vars=c("src","src_SubGroup"))
res_maj_by_group_neighbors_sub_group_m[,mismatch:=F]
res_maj_by_group_neighbors_sub_group_m[src_SubGroup!=variable,mismatch:=T]

res_maj_by_group_neighbors_sub_group_matches=res_maj_by_group_neighbors_sub_group_m[,sum(value),by=list(src,src_SubGroup,variable,mismatch)]
res_maj_by_group_neighbors_sub_group_matches_disagreeing=res_maj_by_group_neighbors_sub_group_matches[mismatch==T]
sub_groups_summaries=res_maj_by_group_neighbors_sub_group_matches_disagreeing[,sum(V1),by=list(src,src_SubGroup,mismatch)]
tbl_df(sub_groups_summaries) %.% group_by(src_SubGroup) %.% summarise(a_mean=mean(V1))
ggplot(sub_groups_summaries,aes(x=factor(V1,levels=0:n_closer_neighbors),fill=src_SubGroup))+geom_histogram()



```